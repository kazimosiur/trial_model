{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"20\">Customer Insights - Predictions - QC Acquisiton</font>\n",
    "\n",
    "1. load data from BigQuery\n",
    "3. definition of features\n",
    "2. per use case: definition of target variables\n",
    "4. predictions for acquisitions\n",
    "5. export data to Google Storage bucket\n",
    "6. data available through BigQuery view\n",
    "\n",
    "[Confluence Documentation](https://confluence.deliveryhero.com/display/DINV/Customer+Segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing, linear_model, ensemble, metrics, model_selection\n",
    "import lightgbm\n",
    "\n",
    "import shap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style('whitegrid')\n",
    "#from jupyterthemes import jtplot #;jtplot.style()\n",
    "\n",
    "import datetime, dateutil\n",
    "import os, sys, yaml, gc, psutil, argparse\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "from IPython.display import display\n",
    "from pprint import PrettyPrinter\n",
    "pprint = PrettyPrinter(indent=1, width=160, compact=True).pprint\n",
    "\n",
    "# main functions for this project\n",
    "sys.path.insert(1, '../')\n",
    "import functions as f\n",
    "\n",
    "sys.path.insert(1, '../../')\n",
    "from utils import utils\n",
    "utils.set_pd_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import watermark\n",
    "print(watermark.watermark(\n",
    "    python=True, hostname=True, machine=True,\n",
    "    packages='pandas,numpy,pyarrow,lightgbm,shap,google.cloud.bigquery,google.cloud.bigquery_storage,google.cloud.storage'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "credentials = service_account.Credentials.from_service_account_file(os.path.expanduser('~')+'/Documents/google_cloud_data-insights-team.json')\n",
    "\n",
    "from google.cloud import bigquery\n",
    "bqclient = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "print(f'connected to BigQuery, project: {bqclient.project}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "storage.blob._DEFAULT_CHUNKSIZE  = 5*1024*1024  # workaround for 60s timeout\n",
    "storage.blob._MAX_MULTIPART_SIZE = 5*1024*1024\n",
    "storage_client = storage.Client(credentials=credentials, project=credentials.project_id)\n",
    "bucket_gs = storage_client.get_bucket('darkstores-data-eng-us')\n",
    "print(f'connected to Google Storage, bucket: {bucket_gs.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_NOTEBOOK = utils.is_notebook()\n",
    "\n",
    "if IS_NOTEBOOK:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %config Completer.use_jedi = False\n",
    "    shap.initjs() # initiate javascript notebook support for shap plots\n",
    "\n",
    "today            = datetime.date.today()\n",
    "this_week_monday = today + datetime.timedelta(days=-today.weekday(),   weeks=0)\n",
    "last_week_sunday = today + datetime.timedelta(days=-today.weekday()-1, weeks=0)\n",
    "today_string            = str(today)[:10]\n",
    "this_week_monday_string = str(this_week_monday)\n",
    "last_week_sunday_string = str(last_week_sunday)\n",
    "\n",
    "print('today:               ', today_string)\n",
    "print('this week monday:    ', this_week_monday)\n",
    "print('last week sunday:    ', last_week_sunday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_PERMUATION_IMP = False\n",
    "N_CORES_ASSIGNED = psutil.cpu_count() - 2 # leave 2 cores free on local machine, increase to full capacity on server\n",
    "\n",
    "# google storage directory\n",
    "DIR_TOPIC = 'customer_insights/acquisition/'\n",
    "DIR_PLOTS = DIR_TOPIC+'plots'\n",
    "\n",
    "# local directory\n",
    "DIR_TMP       = os.path.join(os.path.expanduser('~'), 'tmp')\n",
    "DIR_TMP_PLOTS = os.path.join(DIR_TMP, 'plots')\n",
    "\n",
    "os.makedirs(DIR_TMP,       exist_ok=True)\n",
    "os.makedirs(DIR_TMP_PLOTS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-geid\", \"--global_entity_id\", type=str, default='OTHER')\n",
    "if IS_NOTEBOOK: args = parser.parse_args(\"\")\n",
    "else:           args = parser.parse_args()\n",
    "\n",
    "    \n",
    "if args.global_entity_id=='OTHER':  GLOBAL_ENTITY_ID = 'FP_SG'\n",
    "else:                               GLOBAL_ENTITY_ID = args.global_entity_id\n",
    "\n",
    "GLOBAL_ENTITY_ID = GLOBAL_ENTITY_ID\n",
    "DATE_UNTIL = last_week_sunday_string\n",
    "#DATE_UNTIL = '2021-06-27'\n",
    "print(f'\\n\\n{\"-\"*40}\\n{GLOBAL_ENTITY_ID}, {DATE_UNTIL}\\n{\"-\"*40}\\n\\n')\n",
    "\n",
    "DATE_UNTIL_MINUS_7  = datetime.date.fromisoformat(DATE_UNTIL) - datetime.timedelta(days=7)\n",
    "DATE_UNTIL_MINUS_28 = datetime.date.fromisoformat(DATE_UNTIL) - datetime.timedelta(days=28)\n",
    "\n",
    "try:\n",
    "    del df, export, x_train, x_valid, y_train, y_valid\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## functions\n",
    "should be moved into separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shap_summary_plot(shap_values, feature_df, top_n:int, target:str):\n",
    "    \"create shap summary plot, show and save to GS bucket\"\n",
    "    \n",
    "    shap.summary_plot(shap_values,\n",
    "                      feature_df, \n",
    "                      max_display=top_n, \n",
    "                      show=False)\n",
    "\n",
    "    target_str = target.replace(\"target_\", \"\")\n",
    "    plt.title(f'{target_str}\\n{GLOBAL_ENTITY_ID}, data until {DATE_UNTIL}, top {top_n} features')    \n",
    "    \n",
    "    plot_dir  = os.path.join(DIR_TMP_PLOTS, GLOBAL_ENTITY_ID, target)\n",
    "    plot_path = os.path.join(DIR_TMP_PLOTS, GLOBAL_ENTITY_ID, target, f'shap_{GLOBAL_ENTITY_ID}_{DATE_UNTIL}_{target}.png')\n",
    "    \n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    plt.savefig(plot_path, format='png', dpi=120, bbox_inches='tight')\n",
    "    utils.upload_gs_blob(bucket_gs, plot_path, \n",
    "                         f'{DIR_PLOTS}/entity={GLOBAL_ENTITY_ID}/date={DATE_UNTIL}/target={target}/',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shap_forces_single_row(shap_values_row, feature_names, color=True, top_n=None):\n",
    "    shap_importance = (pd.DataFrame({'feature':feature_names,\n",
    "                                     'shap_importance':shap_values_row})\n",
    "                        .reset_index(drop=True)\n",
    "                      )\n",
    "    shap_importance['shap_importance_abs'] = shap_importance['shap_importance'].abs()\n",
    "    shap_importance['shap_importance_rank'] = shap_importance['shap_importance_abs'].rank(method='average', ascending=False).astype(int)\n",
    "    \n",
    "    shap_importance = (shap_importance\n",
    "                       .sort_values('shap_importance_rank', ascending=True)\n",
    "                       .drop(columns='shap_importance_abs')\n",
    "                       .reset_index(drop=True)\n",
    "                      )\n",
    "\n",
    "    if top_n is not None: shap_importance = shap_importance.head(top_n)\n",
    "    if color: return shap_importance.style.background_gradient(subset='shap_importance', cmap='bwr', low=-0.4, high=0.4)\n",
    "    else:     return shap_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = utils.sql_query_from_placeholders('sql/features_acquisition_qubik.sql',\n",
    "                                          {'GLOBAL_ENTITY_ID':GLOBAL_ENTITY_ID, 'DATE_UNTIL':DATE_UNTIL})\n",
    "# removed date_until from the sql query - now just takes calculations from yesterday's date\n",
    "# print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = f.loaders.read_bigquery(query, bqclient, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtype changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [c for c in df.columns if c.find('date')>=0]\n",
    "\n",
    "for c in date_cols:\n",
    "    try:    df[c] = pd.to_datetime(df[c])\n",
    "    except: print('could not convert to dates:', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BQ transfers data as objects instead of int/float in many cases\n",
    "# to_num_cols = df.drop(columns=['global_entity_id', 'analytical_customer_id']).select_dtypes('object').columns\n",
    "# if len(to_num_cols)>0:\n",
    "#     for c in tqdm(to_num_cols):\n",
    "#         try:\n",
    "#             df[c] = pd.to_numeric(df[c])\n",
    "#         except Exception as e:\n",
    "#             print(c.ljust(40), e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#if IS_NOTEBOOK: \n",
    "(utils\n",
    " .df_info(df.iloc[:, -50:])\n",
    " .style.background_gradient(subset=['isnull_%'], cmap='Reds')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns: print(c, end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(['object', 'category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_catg = ['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, cols_one_hot = f.features.create_one_hot_encoding(df, columns=['visit_last_platform_device'], \n",
    "#                                                       min_pctg_to_keep=0.005)\n",
    "# print('\\nfeatures one hot:', cols_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## geo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cust_lat, cust_long, last_order_h3_level_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lat lon only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lat lon clusters kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in [10, 20, 50, 100]:\n",
    "    start = datetime.datetime.now()\n",
    "    kmeans = KMeans(n_clusters=size)\n",
    "    \n",
    "    kmeans = kmeans.fit(df.loc[:, ['cust_lat', 'cust_long']].head(100_000))\n",
    "    \n",
    "    df[f'cluster_kmeans_{size}'] = kmeans.predict(df.loc[:, ['cust_lat', 'cust_long']])\n",
    "    print(f'kmeans {size:>3}: {(datetime.datetime.now()-start).total_seconds():2.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cust_lat'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(data=df.loc[ :,:#(df['cust_lat']>20)\n",
    "                            #&(df['cust_long']>53)\n",
    "                           ].sample(10_000), x='cust_lat', y='cust_long', hue='cluster_kmeans_10', palette='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(data=df.loc[ (df['cust_lat']>20)\n",
    "                            &(df['cust_long']>53)\n",
    "                           ].sample(10_000), x='cust_lat', y='cust_long', hue='cluster_kmeans_20', palette='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_kmeans = f.features.get_features_list(df, contains=['kmeans'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clusters hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for cluster_size in [200, 500, 1000, 5000, 10000]:\n",
    "    start = datetime.datetime.now()\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=cluster_size, min_samples=50, core_dist_n_jobs=-1)\n",
    "    df[f'cluster_hdbscan_min{cluster_size}'] = clusterer.fit_predict(df.loc[:, ['cust_lat', 'cust_long']].values)\n",
    "    df[f'cluster_hdbscan_min{cluster_size}_outlier_score'] = clusterer.outlier_scores_\n",
    "    print(f'size: {cluster_size}\\t clusters:', df[f'cluster_hdbscan_min{cluster_size}'].nunique(), f'\\t time: {(datetime.datetime.now()-start).total_seconds():2.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_hdbscan = f.features.get_features_list(df, contains=['hdbscan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(data=df.loc[ (df['cust_lat']>20)\n",
    "                            &(df['cust_long']>53)\n",
    "                           ].sample(1_000), x='cust_lat', y='cust_long', hue='cluster_hdbscan_min10000', palette='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kdtree density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kdt = KDTree(data=df.loc[:, ['cust_lat', 'cust_long']].values[:100_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "in_radius_001 = kdt.query_radius(X=df.loc[:, ['cust_lat', 'cust_long']].values, r=0.01)\n",
    "in_radius_001 = [len(a) for a in in_radius_001]\n",
    "df['density_count_radius_0.01'] = in_radius_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "in_radius_003 = kdt.query_radius(X=df.loc[:, ['cust_lat', 'cust_long']].values, r=0.03)\n",
    "in_radius_003 = [len(a) for a in in_radius_003]\n",
    "df['density_count_radius_0.03'] = in_radius_003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(data=df.sample(3_000), \n",
    "                x='cust_long', y='cust_lat',\n",
    "                hue='density_count_radius_0.03', #palette='viridis'\n",
    "               );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_density = ['density_count_radius_0.01', 'density_count_radius_0.03']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h3 hexagons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_order_h3_level_8'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT\n",
    "        h38_id,\n",
    "        CAST(population AS INT64) AS h38_population\n",
    "    FROM `dh-global-sales-data.geolayer.worldpop_h38`\n",
    "    WHERE country_iso IN ('SG', 'AE')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv('h3_population.csv')\n",
    "pop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, pop, how='left', left_on='last_order_h3_level_8', right_on='h38_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_h3 = ['h38_population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_geo = [\n",
    "    'cust_lat', 'cust_long'\n",
    "    ,*features_kmeans\n",
    "    ,*features_hdbscan\n",
    "    ,*features_density\n",
    "    ,*features_h3\n",
    "    ,'dist_nearest_vendor_qc', 'dist_nearest_dmart', 'dist_nearest_localstore'\n",
    "    ,'coverage_vendors_qc', 'coverage_dmart', 'coverage_localstore'\n",
    "    ,'coverage_convenience', 'coverage_groceries', 'coverage_supermarket'\n",
    "    ,'coverage_vendors_qc_in_2000m', 'coverage_vendors_qc_in_4000m', 'coverage_vendors_qc_in_6000m'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.display_df(df.loc[:, features_geo].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9, 0.99]).T#.astype(int)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cluster_hdbscan_min5000_outlier_score'].hist(bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique prefixes\n",
    "if IS_NOTEBOOK:\n",
    "    print(sorted(list(set([col.split('past')[0].split('nv_')[0].split('rs_')[0] \n",
    "                           for col in df.columns]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if IS_NOTEBOOK:\n",
    "#     df['orders_of_visits_l12w'] = (df['order_count_l12w_vert_rs'] / df['visit_count_l12w']).clip(-1, 2)\n",
    "#     df['orders_of_visits_l12w'].hist(bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_qubik = [\n",
    "    ### cause overfit for some reason\n",
    "    #'customer_id_countd', 'visit_vendors_viewed_l04w', 'visit_vendors_available_l04w', 'visit_addresses_unique_l04w', 'visit_count_l04w',\n",
    "    'order_rate_online_payment_l04w',\n",
    "    'visit_count_l12w', 'visit_count_l04w_vs_l12w',\n",
    "    'visit_session_dur_sum_l04w', 'visit_session_dur_avg_l04w',\n",
    "    'visit_interact_speed_avg_l04w', 'visit_cart_abandon_rate_l04w', 'visit_search_fail_rate_l04w', 'visit_voucher_error_rate_l04w',\n",
    "    'rating_avg_l04w', \n",
    "    'aos_score_last', 'aos_rating_last',\n",
    "    'ccc_sessions_l04w',\n",
    "    #'visit_channel_first', 'visit_channel_last', 'visit_last_platform_device', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_df(df.loc[:, features_qubik].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9, 0.99]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.df_info(df.loc[:, features_qubik]).style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cont = f.features.get_features_list(df, 'number', contains=['vert_rs'])\n",
    "#features_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_one_hot = f.features.get_features_list(df, contains=['one_hot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude one-hot for now\n",
    "features_all = (\n",
    "    features_cont\n",
    "    +feat_one_hot\n",
    "    +features_geo\n",
    "    +features_qubik\n",
    ")\n",
    "len(features_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[:, ['dist_nearest_dmart', 'dist_nearest_localstore', 'dist_nearest_vendor_qc']].describe().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generate predictions with a single model\n",
    "- get regular and permutation feature importances\n",
    "- remove useless features\n",
    "- train out-of-fold models with reduced feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquired, if at least one QC order\n",
    "print('='*12, 'general trial probability', '='*12)\n",
    "df, target = f.targets.create_acquisition_general(df)\n",
    "utils.display_value_counts(df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for differences between target groups, check to avoid overfitting, target leakage, etc\n",
    "# (df\n",
    "#  .groupby(target)\n",
    "#  .agg({'days_since_first_order_vert_rs':['mean', 'min', 'max'],\n",
    "#        'days_since_last_order_vert_rs':['mean', 'min', 'max'],\n",
    "#        'voucher_dh_sum_vert_rs_lifetime':['mean', 'min', 'max'],\n",
    "#        'order_amount_gmv_eur_avg_vert_rs_lifetime':['mean', 'min', 'max'],\n",
    "#        'delivery_fee_sum_vert_rs_lifetime':['mean', 'min', 'max'],\n",
    "#        'discount_other_sum_vert_rs_lifetime':['mean', 'min', 'max']\n",
    "#       })\n",
    "#  .reset_index()\n",
    "#  .T\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate simplest possible 'predictions' as a baseline\n",
    "df['preds_acquisition_qc_general_benchmark'] = df[target].mean()\n",
    "\n",
    "print('Benchmark model:', f.metrics.binary_metrics_text(df[target], df['preds_acquisition_qc_general_benchmark']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single train/valid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split with simple 80-20 method\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(\n",
    "    df.loc[:, features_all],\n",
    "    df.loc[:, target],\n",
    "    stratify=df.loc[:, target],\n",
    "    test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'x train: {utils.df_shape(x_train).rjust(17)} | y_train:', f'{len(y_train):>9,} | mean {y_train.mean():,.6f}')\n",
    "print(f'x valid: {utils.df_shape(x_valid).rjust(17)} | y_valid:', f'{len(y_valid):>9,} | mean {y_valid.mean():,.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic parameters, not too deep, some regularization with min_child_samples and 80% feature use\n",
    "params_init = {\n",
    "    'objective':'binary',  'learning_rate': 0.08, 'n_estimators': 2000, 'min_split_gain': 0.003,\n",
    "    'num_leaves': 2**7-1, 'max_depth': 7, 'min_child_samples': 200, 'colsample_bytree': 0.8, \n",
    "    'reg_alpha': 0.5, 'reg_lambda': 0.5,\n",
    "    'n_jobs': N_CORES_ASSIGNED, 'random_state': 42, \n",
    "    'verbose': -1, #'force_col_wise':True\n",
    "}\n",
    "model_lgb = lightgbm.LGBMClassifier(**params_init)\n",
    "\n",
    "model_lgb.fit(X=x_train, y=y_train,\n",
    "              eval_set=(x_valid, y_valid),\n",
    "              early_stopping_rounds=20, verbose=100);\n",
    "\n",
    "y_pred = model_lgb.predict_proba(x_valid)[:,1]\n",
    "\n",
    "print()\n",
    "print('LightGBM model: ', f.metrics.binary_metrics_text(y_valid, y_pred))\n",
    "print('Benchmark model:', f.metrics.binary_metrics_text(df[target], df['preds_acquisition_qc_general_benchmark']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NOTEBOOK:\n",
    "    plt.title(f'acquisition probability into QC - {GLOBAL_ENTITY_ID}, data until {DATE_UNTIL}')\n",
    "    sns.histplot(pd.Series(y_pred), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_imp = f.features.feat_importances_from_models([model_lgb], features_all)\n",
    "feat_imp['feature'] = feat_imp['feature'].apply(lambda s: s.replace('ft_', '').split('__fillna_')[0])\n",
    "\n",
    "if IS_NOTEBOOK:\n",
    "    display(feat_imp\n",
    "            .loc[#feat_imp['feature'].str.contains('device')\n",
    "                 :\n",
    "                 , ['feature', 'imp_mean']]\n",
    "            #.query('imp_mean > 0.02')\n",
    "            .head(30)\n",
    "            .style.bar(color='#93a2be')\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes around 30s\n",
    "sample_size = 500\n",
    "print(f'creating TreeExplainer')\n",
    "explainer = shap.TreeExplainer(\n",
    "    model=model_lgb,\n",
    "    data=x_valid[:sample_size], # will run a lot slower when passing data\n",
    "    #data=x_valid_target.loc[x_valid_target['pred']>0.99, features_all],\n",
    "    #feature_perturbation='interventional',\n",
    "    model_output='probability',\n",
    "    #model_output='raw_value'\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X=x_valid[:sample_size], y=None)\n",
    "\n",
    "shap_values_1 = explainer(x_valid[:sample_size])\n",
    "\n",
    "shap_values_df = pd.DataFrame(shap_values, columns=features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:    shap_summary_plot(shap_values, x_valid[:sample_size], 20, target)\n",
    "except: print('ERROR plotting shap values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for feat in feat_imp['feature'].head(10):\n",
    "#     shap.plots.scatter(shap_values_1[:,feat])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overfit check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_target = x_valid.copy()\n",
    "x_valid_target['target'] = y_valid\n",
    "x_valid_target['pred']   = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_target['pred'].hist(bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit = x_valid_target.loc[\n",
    "#     x_valid_target['pred']>0.999\n",
    "#     ,['pred', 'target', 'days_since_first_order_vert_rs', 'gmv_sum_l04w_vert_rs', \n",
    "#       'order_count_l04w_vert_rs', 'order_count_l16w_vert_rs', 'rating_avg_l04w',\n",
    "#       'dist_nearest_dmart', \n",
    "#      ]\n",
    "# ]\n",
    "\n",
    "# normal = x_valid_target.loc[\n",
    "#     (x_valid_target['pred']>0.2) & (x_valid_target['pred']<0.21)\n",
    "#     ,['pred', 'target', 'days_since_first_order_vert_rs', 'gmv_sum_l04w_vert_rs',\n",
    "#       'order_count_l04w_vert_rs', 'order_count_l16w_vert_rs', 'rating_avg_l04w',\n",
    "#       'dist_nearest_dmart', \n",
    "#      ]\n",
    "# ]\n",
    "# print(overfit.shape, normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### permutation importance\n",
    "currently requires no missing values, see [PR](https://github.com/eli5-org/eli5/pull/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_PERMUATION_IMP:\n",
    "    # takes a few minutes, doesn't work with NaN, unfortunately\n",
    "    print('permutation importance: calculating...')\n",
    "    perm_imp = f.features.permutation_importance(model_lgb, x_valid[:100_000].fillna(-1), y_valid[:100_000], n_iter=1)\n",
    "\n",
    "    feature_selection = list(perm_imp.query('perm_imp>0')['feature'].values)\n",
    "    # features_relevant\n",
    "    print(f'features: {len(features_relevant)}/{len(features_all)}')\n",
    "    \n",
    "    perm_imp.style.background_gradient()\n",
    "else:\n",
    "    print('permutation importance: deactivated')\n",
    "    feature_selection = features_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### out of fold predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Logistic Regression\n",
    "has some bugs with the solver currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# params_init = {\n",
    "#     'random_state':42\n",
    "# }\n",
    "\n",
    "# model = linear_model.LogisticRegression(**params_init)\n",
    "\n",
    "# y_pred_classes = model_selection.cross_val_predict(\n",
    "#     estimator=model, \n",
    "#     method='predict_proba',\n",
    "#     X=df[features_relevant].fillna(-1), # works best with -1, need to find a better imputation\n",
    "#     y=df[target], \n",
    "#     cv=8, n_jobs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# y_pred_1 = y_pred_classes[:,1]\n",
    "# df['preds_oof_acquisition_qc__0_1__logreg'] = y_pred_1\n",
    "\n",
    "# print(f.metrics.binary_metrics_text(df[target], df['preds_oof_acquisition_qc__0_1__logreg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# params_init = {\n",
    "#     'random_state':42\n",
    "# }\n",
    "\n",
    "# df, models = sl.learn.predict_out_of_fold_sklearn(\n",
    "#     df.fillna(-1), train_index=df.index, \n",
    "#     predict_index=None, # complete oof-predictions, no pred-only data\n",
    "#     target='target_acquisition_qc__0_1', \n",
    "#     features=features_relevant,\n",
    "#     n_splits=5,\n",
    "#     preds_oof_col_suffix='acquisition_qc__0_1__logreg', \n",
    "#     est=linear_model.LogisticRegression,\n",
    "#     predict_method='predict_proba',\n",
    "#     model_init_params=params_init\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create out of fold predictions with custom functions.\n",
    "Uses less memory and returns the used models for further usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('generating predictions for trial probability...')\n",
    "params_init = {\n",
    "    'objective':'binary',  'learning_rate': 0.10, 'n_estimators': 2000, 'min_split_gain': 0.005,\n",
    "    'num_leaves': 2**7-1, 'max_depth': 7, 'min_child_samples': 200, 'colsample_bytree': 0.8, \n",
    "    'reg_alpha': 0.5, 'reg_lambda': 0.5,\n",
    "    'n_jobs': N_CORES_ASSIGNED, 'random_state': 42, \n",
    "    'verbose': -1, #'force_col_wise':True\n",
    "}\n",
    "\n",
    "df, models = f.models.predict_out_of_fold_sklearn(\n",
    "    df, train_index=df.index, \n",
    "    predict_index=None, # complete oof-predictions, no pred-only data\n",
    "    target=target, \n",
    "    features=feature_selection,\n",
    "    n_splits=5,\n",
    "    preds_oof_col_suffix='acquisition_qc_general_0_1_lgb', \n",
    "    est=lightgbm.LGBMClassifier, predict_method='predict_proba',\n",
    "    model_init_params=params_init,\n",
    "    model_fit_params={'verbose':50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.metrics.binary_metrics_text(df[target], df['preds_oof_acquisition_qc_general_0_1_lgb']))\n",
    "metrics_acq_gen = pd.DataFrame(data=f.metrics.binary_metrics(df[target], df['preds_oof_acquisition_qc_general_0_1_lgb']), index=[0])\n",
    "display(metrics_acq_gen)\n",
    "\n",
    "# pd.crosstab(index=  df['target_acquisition_qc_general_0_1'],\n",
    "#             columns=df['preds_oof_acquisition_qc_general_0_1_lgb'].apply(round),\n",
    "#                          values='analytical_customer_id', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_imp = f.features.feat_importances_from_models(models, feature_selection)\n",
    "feat_imp['feature'] = feat_imp['feature'].apply(lambda s: s.replace('ft_', '').split('__fillna_')[0])\n",
    "\n",
    "utils.df_to_gs(feat_imp, bucket_gs, f'{DIR_TOPIC}feat_imp/entity={GLOBAL_ENTITY_ID}/target={target}/date={DATE_UNTIL}/feat_imp.parquet', verbose=False)\n",
    "\n",
    "if IS_NOTEBOOK:\n",
    "    display(feat_imp\n",
    "            .loc[:, ['feature', 'imp_mean']]\n",
    "            #.query('imp_mean > 0.02')\n",
    "            .head(10)\n",
    "            .style.bar(color='#93a2be')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NOTEBOOK:\n",
    "    plt.title(f'acquisition probability into QC - {GLOBAL_ENTITY_ID}, data until {DATE_UNTIL}')\n",
    "    sns.histplot(df['preds_oof_acquisition_qc_general_0_1_lgb'], bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine predictions from multiple models.. add other predictions if more models are used\n",
    "\n",
    "#df['preds_oof_acquisition_qc__0_1__final'] = ( df['preds_oof_acquisition_qc__0_1__lgb'] * 0.9\n",
    "#                                              +df['preds_oof_acquisition_qc__0_1__logreg'] * 0.1)\n",
    "df['preds_'+'acquisition_qc_general_0_1'+'_final'] = ( df['preds_oof_acquisition_qc_general_0_1_lgb']#*0.5\n",
    "                                                      #+df['preds_oof_acquisition_qc_0_1_lgb']*0.5\n",
    "                                                     )\n",
    "\n",
    "#print('LogReg:    ', f.metrics.binary_metrics_text(df[target], df['preds_oof_acquisition_qc__0_1__logreg']))\n",
    "print('LightGBM 1:', f.metrics.binary_metrics_text(df[target], df['preds_oof_acquisition_qc_general_0_1_lgb']))\n",
    "#print('LightGBM 2:', f.metrics.binary_metrics_text(df[target], df['preds_oof_acquisition_qc_0_1_lgb2']))\n",
    "#print('combined:  ', f.metrics.binary_metrics_text(df[target], df['preds_'+'acquisition_qc_general_0_1'+'_final']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NOTEBOOK:\n",
    "    plt.title(f'distribution actual vs predicted: {GLOBAL_ENTITY_ID}, data until {DATE_UNTIL}')\n",
    "    sns.histplot(df, x='preds_oof_acquisition_qc_general_0_1_lgb', bins=50, hue=target, kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df.sample(10000), x='order_hour_avg_l16w_vert_rs', bins=24*2, \n",
    "#              hue='target_acquisition_qc_general_0_1', kde=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## organic acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*12, 'organic vs paid trial', '='*12)\n",
    "df, target = f.targets.create_acquisition_organic(df)\n",
    "\n",
    "utils.display_value_counts(df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = df.loc[df[target].notnull(), :].index\n",
    "index_pred  = df.loc[df[target].isnull(),  :].index\n",
    "print(f'train: {len(index_train):,} pred: {len(index_pred):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate simplest possible 'predictions' as a baseline\n",
    "avg = df.loc[df['order_count_lifetime_vert_qc']>0, target].mean()\n",
    "df['preds_acquisition_qc_organic_0_1_benchmark'] = avg\n",
    "\n",
    "print('benchmark model:', f.metrics.binary_metrics_text(\n",
    "    df.loc[df['order_count_lifetime_vert_qc']>0, target],\n",
    "    df.loc[df['order_count_lifetime_vert_qc']>0, 'preds_acquisition_qc_organic_0_1_benchmark']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single train/valid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split with simple 80-20 method\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(\n",
    "    df.loc[index_train, features_all],\n",
    "    df.loc[index_train, target],\n",
    "    stratify=df.loc[index_train, target],\n",
    "    test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'x train: {utils.df_shape(x_train).rjust(16)} | y_train:', f'{len(y_train):>9,} | mean {y_train.mean():,.6f}')\n",
    "print(f'x valid: {utils.df_shape(x_valid).rjust(16)} | y_valid:', f'{len(y_valid):>9,} | mean {y_valid.mean():,.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic parameters, not too deep, some regularization with min_child_samples and 80% feature use\n",
    "params_init = {\n",
    "    'objective':'binary',  'learning_rate': 0.05, 'n_estimators': 2000,\n",
    "    'num_leaves': 2**7-1, 'max_depth': 7, 'min_child_samples': 100, 'colsample_bytree': 0.8, \n",
    "    'reg_alpha': 0.5, 'reg_lambda': 0.5,\n",
    "    'n_jobs': N_CORES_ASSIGNED, 'random_state': 42, 'verbose': -1\n",
    "}\n",
    "model_lgb = lightgbm.LGBMClassifier(**params_init)\n",
    "\n",
    "model_lgb.fit(X=x_train, y=y_train,\n",
    "              eval_set=(x_valid, y_valid),\n",
    "              early_stopping_rounds=20, verbose=False);\n",
    "\n",
    "y_pred = model_lgb.predict_proba(x_valid)[:,1]\n",
    "y_pred_01 = np.round(y_pred, 0)\n",
    "\n",
    "print('LightGBM model: ', f.metrics.binary_metrics_text(y_valid, y_pred))\n",
    "print('benchmark model:', f.metrics.binary_metrics_text(\n",
    "    df.loc[df['order_count_lifetime_vert_qc']>0, target],\n",
    "    df.loc[df['order_count_lifetime_vert_qc']>0, 'preds_acquisition_qc_organic_0_1_benchmark']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 500\n",
    "print(f'creating TreeExplainers')\n",
    "explainer = shap.TreeExplainer(\n",
    "    model=model_lgb,\n",
    "    data=x_valid[:sample_size], # will run a lot slower when passing data\n",
    "    #feature_perturbation='interventional',\n",
    "    model_output='probability',\n",
    "    #model_output='raw_value'\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X=x_valid[:sample_size], y=None)\n",
    "\n",
    "try: shap_summary_plot(shap_values, x_valid[:sample_size], 20, target)\n",
    "except: print('ERROR plotting shap values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### out of fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create out of fold predictions with custom functions.\n",
    "Uses less memory and returns the used models for further usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('generating out-of-fold predictions for organic vs paid probability...')\n",
    "params_init = {\n",
    "    'objective':'binary',  'learning_rate': 0.05, 'n_estimators': 1000,\n",
    "    'num_leaves': 2**7-1, 'max_depth': 7, 'min_child_samples': 100, 'colsample_bytree': 0.8, \n",
    "    'reg_alpha': 0.5, 'reg_lambda': 0.5,\n",
    "    'n_jobs': N_CORES_ASSIGNED, 'random_state': 42, 'verbose': -1\n",
    "}\n",
    "\n",
    "# train on 5-split actual data, predict on out-of-fold actual data + open customers\n",
    "df, models = f.models.predict_out_of_fold_sklearn(\n",
    "    df,\n",
    "    train_index=index_train, \n",
    "    predict_index=index_pred,\n",
    "    target=target, \n",
    "    features=features_all,\n",
    "    n_splits=5,\n",
    "    preds_oof_col_suffix='acquisition_qc_organic_0_1_lgb', \n",
    "    est=lightgbm.LGBMClassifier, predict_method='predict_proba',\n",
    "    model_init_params=params_init,\n",
    "    model_fit_params={'verbose':50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_acq_org = pd.DataFrame(data=f.metrics.binary_metrics(df.loc[index_train, target],\n",
    "                                                             df.loc[index_train, 'preds_oof_acquisition_qc_organic_0_1_lgb']), index=[0])\n",
    "display(metrics_acq_org)\n",
    "display(pd.crosstab(index=  df.loc[index_train, 'target_acquisition_qc_organic_0_1'],\n",
    "                    columns=df.loc[index_train, 'preds_oof_acquisition_qc_organic_0_1_lgb'].apply(round),\n",
    "                    values='analytical_customer_id', aggfunc='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NOTEBOOK: sns.histplot(df, x='preds_oof_acquisition_qc_organic_0_1_lgb', bins=100, \n",
    "                             #hue=target,\n",
    "                             kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_imp = f.features.feat_importances_from_models(models, features_all)\n",
    "feat_imp['feature'] = feat_imp['feature'].apply(lambda s: s.replace('ft_', '').split('__fillna_')[0])\n",
    "\n",
    "utils.df_to_gs(feat_imp, bucket_gs, f'{DIR_TOPIC}feat_imp/entity={GLOBAL_ENTITY_ID}/target={target}/date={DATE_UNTIL}/feat_imp.parquet', verbose=False)\n",
    "\n",
    "if IS_NOTEBOOK: \n",
    "    display(feat_imp\n",
    "            .loc[:, ['feature', 'imp_mean']]\n",
    "            #.query('imp_mean > 0.02')\n",
    "            .head(10)\n",
    "            .style.bar(color='#93a2be')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final prediction, add other models (ensemble) in the future\n",
    "df['preds_'+'acquisition_qc_organic_0_1'+'_final'] = (df['preds_oof_acquisition_qc_organic_0_1_lgb']\n",
    "                                                      #+df['preds_oof_acquisition_qc_organic_0_1_logreg']\n",
    "                                                     )#/2\n",
    "print('rows with missing predictions:', df['preds_'+'acquisition_qc_organic_0_1'+'_final'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order frequency\n",
    "Predict monthly order frequency after acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*12, 'order frequency', '='*12)\n",
    "df, target = f.targets.create_acquisition_order_freq_4w_qc(df)\n",
    "\n",
    "print('\\ndistribution of actual frequencies:', end='')\n",
    "display(df[target].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and prediction index. Train on QC customers, active >=7d. Predict on non-active customers.\n",
    "index_train = df.loc[ (df['order_count_lifetime_vert_qc']> 1)\n",
    "                     &(df['first_order_date_vert_qc']<pd.Timestamp(DATE_UNTIL_MINUS_28))\n",
    "                     &(df[target].notnull()),  :].index\n",
    "\n",
    "index_pred  = df.loc[(df['order_count_lifetime_vert_qc']<=1),  :].index\n",
    "\n",
    "print(f'train: {len(index_train):,} | predict: {len(index_pred):,}')\n",
    "print('missing targets:', df.loc[index_train, target].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p99 = df[target].quantile(0.99)\n",
    "if IS_NOTEBOOK: \n",
    "    plt.title(f'{target}, {GLOBAL_ENTITY_ID}, data until {DATE_UNTIL}')\n",
    "    df.loc[index_train, target].clip(0, p99).hist(bins=int(p99));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# generate simplest possible 'predictions' as a baseline\n",
    "avg = df.loc[df[target].notnull(), target].mean()\n",
    "df['preds_order_freq_4w_vert_qc_benchmark'] = avg\n",
    "\n",
    "print('benchmark model:', f.metrics.regression_metrics_text(\n",
    "    df.loc[df[target].notnull(), target],\n",
    "    df.loc[df[target].notnull(), 'preds_order_freq_4w_vert_qc_benchmark']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single train/valid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if IS_NOTEBOOK:\n",
    "#     display(df.loc[#index_train\n",
    "#         df[target]==3.5\n",
    "#         , ['first_order_date_vert_qc', \n",
    "#            'order_count_lifetime_vert_qc', 'order_freq_4w_vert_qc']].sample(10))                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split with simple 80-20 method\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(\n",
    "    df.loc[index_train, features_all],\n",
    "    df.loc[index_train, target],\n",
    "    test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'x train: {utils.df_shape(x_train).rjust(16)} | y_train:', f'{len(y_train):>9,} | mean {y_train.mean():,.6f}')\n",
    "print(f'x valid: {utils.df_shape(x_valid).rjust(16)} | y_valid:', f'{len(y_valid):>9,} | mean {y_valid.mean():,.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic parameters, not too deep, some regularization with min_child_samples and 80% feature use\n",
    "params_init = {\n",
    "    'learning_rate': 0.02, 'n_estimators': 2000,\n",
    "    'num_leaves': 2**7-1, 'max_depth': 7, 'min_child_samples': 100, 'colsample_bytree': 0.8, \n",
    "    'reg_alpha': 0.5, 'reg_lambda': 0.5,\n",
    "    'n_jobs': N_CORES_ASSIGNED, 'random_state': 42, \n",
    "    'verbose': -1\n",
    "}\n",
    "model_lgb = lightgbm.LGBMRegressor(**params_init)\n",
    "\n",
    "model_lgb.fit(X=x_train, y=y_train,\n",
    "              eval_set=(x_valid, y_valid),\n",
    "              early_stopping_rounds=20, verbose=50);\n",
    "\n",
    "y_pred = model_lgb.predict(x_valid).clip(0.01, None)\n",
    "best_iter = model_lgb.best_iteration_\n",
    "\n",
    "print('LightGBM model: ', f.metrics.regression_metrics_text(y_valid, y_pred))\n",
    "print('benchmark model:', f.metrics.regression_metrics_text(\n",
    "    df.loc[df[target].notnull(), target],\n",
    "    df.loc[df[target].notnull(), 'preds_order_freq_4w_vert_qc_benchmark']))\n",
    "\n",
    "metrics_freq = pd.DataFrame(data=f.metrics.regression_metrics(y_valid, y_pred), index=[0])\n",
    "#display(metrics_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = f.features.feat_importances_from_models([model_lgb], features_all)\n",
    "feat_imp['feature'] = feat_imp['feature'].apply(lambda s: s.replace('ft_', '').split('__fillna_')[0])\n",
    "\n",
    "utils.df_to_gs(feat_imp, bucket_gs, f'{DIR_TOPIC}feat_imp/entity={GLOBAL_ENTITY_ID}/target={target}/date={DATE_UNTIL}/feat_imp.parquet', verbose=False)\n",
    "\n",
    "if IS_NOTEBOOK:\n",
    "    display(feat_imp\n",
    "            .loc[:, ['feature', 'imp_mean']]\n",
    "            #.query('imp_mean > 0.02')\n",
    "            .head(10)\n",
    "            .style.bar(color='#93a2be')\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 500\n",
    "print(f'creating TreeExplainer')\n",
    "explainer = shap.TreeExplainer(\n",
    "    model=model_lgb,\n",
    "    data=x_valid[:sample_size], # will run a lot slower when passing data\n",
    "    #feature_perturbation='interventional',\n",
    "    #model_output='predict_proba',\n",
    "    #model_output='raw_value'\n",
    ")\n",
    "\n",
    "shap_values = explainer.shap_values(X=x_valid[:sample_size], y=None,\n",
    "                                    check_additivity=False # creates errors otherwise\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try: shap_summary_plot(shap_values, x_valid[:sample_size], 20, target)\n",
    "except: print('ERROR plotting shap values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on non-acquired customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic parameters, same iterations as previous model\n",
    "print(f'training on {len(index_train):,} acquired and predicting on {len(index_pred):,} non-acquired customers')\n",
    "params_init = {\n",
    "    'learning_rate': 0.02, 'n_estimators': best_iter+10,\n",
    "    'num_leaves': 2**7-1, 'max_depth': 7, 'min_child_samples': 100, 'colsample_bytree': 0.8, \n",
    "    'reg_alpha': 0.5, 'reg_lambda': 0.5,\n",
    "    'n_jobs': N_CORES_ASSIGNED, 'random_state': 42, \n",
    "    'verbose': -1\n",
    "}\n",
    "model_lgb = lightgbm.LGBMRegressor(**params_init)\n",
    "\n",
    "model_lgb.fit(X=df.loc[index_train, features_all],\n",
    "              y=df.loc[index_train, target],\n",
    "              verbose=50);\n",
    "\n",
    "y_pred = model_lgb.predict(df.loc[index_pred, features_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NOTEBOOK:\n",
    "    p99 = pd.Series(y_pred).quantile(0.99)\n",
    "    pd.Series(y_pred).clip(0,p99).hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[index_pred, 'preds_'+'order_freq_4w_vert_qc'] = y_pred\n",
    "\n",
    "# insert additional logic (ensembles) later\n",
    "df['preds_'+'order_freq_4w_vert_qc'+'_final'] = df['preds_'+'order_freq_4w_vert_qc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order value - check 0 values\n",
    "Predict average order value after acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*12, 'average order value', '='*12)\n",
    "\n",
    "if df.loc[df['order_count_lifetime_vert_qc']>0,\n",
    "          'gmv_avg_lifetime_vert_qc'].isnull().sum():\n",
    "    raise Exception('missing GMV AVG on vert QC')\n",
    "\n",
    "df, target = f.targets.create_acquisition_gmv_avg_qc(df)\n",
    "\n",
    "print('\\ndistribution of actual frequencies:', end='')\n",
    "display(df[target].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = df.loc[ (df['order_count_lifetime_vert_qc']> 1)\n",
    "                     &(df['first_order_date_vert_qc']<pd.Timestamp(DATE_UNTIL_MINUS_28))\n",
    "                     &(df[target].notnull()),  :].index\n",
    "\n",
    "index_pred  = df.loc[(df['order_count_lifetime_vert_qc']<=1),  :].index\n",
    "\n",
    "print(f'train: {len(index_train):,} | predict: {len(index_pred):,}')\n",
    "print('missing targets:', df.loc[index_train, target].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p99 = df[target].quantile(0.99)\n",
    "if IS_NOTEBOOK: df.loc[index_train, target].clip(0, p99).hist(bins=int(p99)*2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate simplest possible 'predictions' as a baseline\n",
    "avg = df.loc[df[target].notnull(), target].mean()\n",
    "df['preds_gmv_avg_lifetime_vert_qc_benchmark'] = avg\n",
    "\n",
    "print('benchmark model:', f.metrics.regression_metrics_text(\n",
    "    df.loc[df[target].notnull(), target],\n",
    "    df.loc[df[target].notnull(), 'preds_gmv_avg_lifetime_vert_qc_benchmark']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single train/valid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split with simple 80-20 method\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(\n",
    "    df.loc[index_train, features_all],\n",
    "    df.loc[index_train, target],\n",
    "    test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'x train: {utils.df_shape(x_train).rjust(16)} | y_train:', f'{len(y_train):>9,} | mean {y_train.mean():,.6f}')\n",
    "print(f'x valid: {utils.df_shape(x_valid).rjust(16)} | y_valid:', f'{len(y_valid):>9,} | mean {y_valid.mean():,.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# basic parameters, not too deep, some regularization with min_child_samples and 80% feature use\n",
    "params_init = {\n",
    "    'learning_rate': 0.02, 'n_estimators': 2000,\n",
    "    'num_leaves': 2**7-1, 'max_depth': 7, 'min_child_samples': 100, 'colsample_bytree': 0.8, \n",
    "    'reg_alpha': 0.5, 'reg_lambda': 0.5,\n",
    "    'n_jobs': N_CORES_ASSIGNED, 'random_state': 42, \n",
    "    'verbose': -100\n",
    "}\n",
    "model_lgb = lightgbm.LGBMRegressor(**params_init)\n",
    "\n",
    "model_lgb.fit(X=x_train, y=y_train,\n",
    "              eval_set=(x_valid, y_valid),\n",
    "              early_stopping_rounds=20, verbose=50);\n",
    "\n",
    "y_pred = model_lgb.predict(x_valid)\n",
    "best_iter = model_lgb.best_iteration_\n",
    "\n",
    "print('best iteration:', best_iter)\n",
    "print('LightGBM model: ', f.metrics.regression_metrics_text(y_valid, y_pred))\n",
    "print('benchmark model:', f.metrics.regression_metrics_text(\n",
    "    df.loc[df[target].notnull(), target],\n",
    "    df.loc[df[target].notnull(), 'preds_gmv_avg_lifetime_vert_qc_benchmark']))\n",
    "\n",
    "metrics_aov = pd.DataFrame(data=f.metrics.regression_metrics(y_valid, y_pred), index=[0])\n",
    "#display(metrics_aov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM model:  mse: 83.3652\trmse: 9.1305\tmae: 4.8708\tr2: 0.1230\ty_pred_<=0: 0.0000\ty_pred_max: 53.8100\tstd: 3.4669\t2021-05-24 18:02:26\n",
    "# LightGBM model:  mse: 81.8974\trmse: 9.0497\tmae: 4.7790\tr2: 0.1384\ty_pred_<=0: 0.0000\ty_pred_max: 47.2400\tstd: 3.5837\t2021-05-24 19:50:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = f.features.feat_importances_from_models([model_lgb], features_all)\n",
    "feat_imp['feature'] = feat_imp['feature'].apply(lambda s: s.replace('ft_', '').split('__fillna_')[0])\n",
    "\n",
    "utils.df_to_gs(feat_imp, bucket_gs, f'{DIR_TOPIC}feat_imp/entity={GLOBAL_ENTITY_ID}/target={target}/date={DATE_UNTIL}/feat_imp.parquet', verbose=False)\n",
    "\n",
    "if IS_NOTEBOOK:\n",
    "    display(feat_imp\n",
    "            .loc[:, ['feature', 'imp_mean']]\n",
    "            #.query('imp_mean > 0.02')\n",
    "            .head(10)\n",
    "            .style.bar(color='#93a2be')\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 500\n",
    "print(f'creating TreeExplainer')\n",
    "explainer = shap.TreeExplainer(\n",
    "    model=model_lgb,\n",
    "    data=x_valid[:sample_size], # will run a lot slower when passing data\n",
    "    #feature_perturbation='interventional',\n",
    "    #model_output='predict_proba',\n",
    "    #model_output='raw_value',\n",
    "    check_additivity=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some weird behaviours.. check if this works, then continue with the next one as well\n",
    "works = False\n",
    "try:\n",
    "    shap_values = explainer.shap_values(X=x_valid[:sample_size], y=None)\n",
    "    works = True\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#shap_values_1 = explainer(x_valid[:sample_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if works:\n",
    "    try:\n",
    "        shap_summary_plot(shap_values, x_valid[:sample_size], 20, target)\n",
    "    except:\n",
    "        print('ERROR plotting shap values')\n",
    "else:\n",
    "    print('cant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for feat in feat_imp['feature'].head(10):\n",
    "#     shap.plots.scatter(shap_values_1[:,feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on non-acquired customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic parameters, same iterations as previous model\n",
    "print(f'training on {len(index_train):,} acquired and predicting on {len(index_pred):,} non-acquired customers')\n",
    "params_init = {\n",
    "    'learning_rate': 0.02, 'n_estimators': best_iter+10,\n",
    "    'num_leaves': 2**7-1, 'max_depth': 7, 'min_child_samples': 100, 'colsample_bytree': 0.8, \n",
    "    'reg_alpha': 0.5, 'reg_lambda': 0.5,\n",
    "    'n_jobs': N_CORES_ASSIGNED, 'random_state': 42, \n",
    "    'verbose': -1\n",
    "}\n",
    "model_lgb = lightgbm.LGBMRegressor(**params_init)\n",
    "\n",
    "model_lgb.fit(X=df.loc[index_train, features_all],\n",
    "              y=df.loc[index_train, target],\n",
    "              verbose=50);\n",
    "\n",
    "y_pred = model_lgb.predict(df.loc[index_pred, features_all])\n",
    "\n",
    "print(f'y_pred: mean {y_pred.mean():.2f}, std {y_pred.std():.2f}, min {y_pred.min():.2f}, max {y_pred.max():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular predictions and percentiles\n",
    "df.loc[index_pred, 'preds_'+'gmv_avg_lifetime_vert_qc'] = y_pred\n",
    "\n",
    "# insert additional logic (ensemble) later\n",
    "df['preds_'+'gmv_avg_lifetime_vert_qc'+'_final'] = df['preds_'+'gmv_avg_lifetime_vert_qc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NOTEBOOK: \n",
    "    p995 = pd.Series(y_pred).quantile(0.995)    \n",
    "    pd.Series(y_pred).clip(0,p995).hist(bins=int(p995)*2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all = pd.concat(objs=[metrics_acq_gen, metrics_acq_org, metrics_freq, metrics_aov])\n",
    "metrics_all.index = ['target_acquisition_qc_general_0_1', 'target_acquisition_qc_organic_0_1', 'target_order_freq_4w_vert_qc', 'target_gmv_avg_lifetime_vert_qc']\n",
    "metrics_all.index.name = 'target'\n",
    "metrics_all = metrics_all.reset_index()\n",
    "display(metrics_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.df_to_gs(metrics_all, bucket_gs, f'{DIR_TOPIC}metrics/entity={GLOBAL_ENTITY_ID}/date={DATE_UNTIL}/metrics_all_targets.parquet', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = sorted([col for col in df.columns if col.startswith('target')])\n",
    "pred_cols   = sorted([col for col in df.columns if col.startswith('preds') and col.endswith('final') and col!='preds_benchmark'])\n",
    "print(f'found {len(target_cols)} targets, {(len(pred_cols))} prediction columns')\n",
    "\n",
    "if IS_NOTEBOOK: \n",
    "    print(target_cols)\n",
    "    print(pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "export = (df\n",
    "          .loc[:, [\n",
    "              'analytical_customer_id', *target_cols, *pred_cols,\n",
    "           ]]\n",
    "          .sort_values('analytical_customer_id') # sort for BigQuery optimization\n",
    "          .reset_index(drop=True)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['target_acquisition_qc_organic_0_1', 'target_gmv_avg_lifetime_vert_qc', 'target_order_freq_4w_vert_qc',\n",
    "          'preds_acquisition_qc_general_0_1_final', 'preds_acquisition_qc_organic_0_1_final',\n",
    "          'preds_gmv_avg_lifetime_vert_qc_final', 'preds_order_freq_4w_vert_qc_final']:\n",
    "    export[p] = export[p].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NOTEBOOK: display(utils.df_info(export))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# utils.df_to_gs(\n",
    "#     export, bucket_gs, \n",
    "#     f'{DIR_TOPIC}predictions/entity={GLOBAL_ENTITY_ID}/date={DATE_UNTIL}/preds.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "580px",
    "left": "99px",
    "top": "131px",
    "width": "287.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "538px",
    "left": "1070px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
